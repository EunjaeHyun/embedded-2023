{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunjaeHyun/embedded-2023/blob/main/ResNet_rev_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy3NP4fsmgev",
        "outputId": "863d88d1-464c-4830-fa12-e90f558d0453"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-06 22:25:59.537411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-06 22:25:59.537443: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-06 22:25:59.537469: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-06 22:25:59.545142: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-06 22:26:00.315180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow_model_optimization\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers, datasets, utils, callbacks, optimizers, losses\n",
        "from keras.datasets import cifar10\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXOtrXiImuXd",
        "outputId": "531015b0-1652-4c59-9a14-0640e9be882e"
      },
      "outputs": [],
      "source": [
        "# Loading data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Data Transform\n",
        "x_train = x_train.astype(np.float32) / 255.0\n",
        "y_train = utils.to_categorical(y_train)\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "\n",
        "x_test = x_test.astype(np.float32) / 255.0\n",
        "y_test = utils.to_categorical(y_test)\n",
        "x_test -= x_train_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdAgZtly1_XW"
      },
      "source": [
        "### ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MyQ5WtkTnGmO"
      },
      "outputs": [],
      "source": [
        "# # @title 기본 제목 텍스트\n",
        "# kernel_initializer = 'he_normal'\n",
        "# input_shape = (32,32,3)\n",
        "\n",
        "# image_input = layers.Input(shape=input_shape)\n",
        "# # first layer\n",
        "\n",
        "# block1 = keras.Sequential([\n",
        "#     layers.Conv2D(kernel_size=3, filters=64, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU()\n",
        "# ])(image_input)\n",
        "\n",
        "# # first stage\n",
        "# shortcut = block1\n",
        "# block2 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block1)\n",
        "\n",
        "# block2 = layers.add([block2, shortcut])\n",
        "# block2 = layers.ReLU()(block2)\n",
        "\n",
        "# shortcut = block2\n",
        "# block3 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block2)\n",
        "\n",
        "# block3 = layers.add([block3, shortcut])\n",
        "# block3 = layers.ReLU()(block3)\n",
        "\n",
        "# # second stage\n",
        "# shortcut = keras.Sequential([layers.Conv2D(filters=128, kernel_size=1, strides=2),\n",
        "#                              layers.BatchNormalization()])(block3)\n",
        "# block4 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block3)\n",
        "\n",
        "# block4 = layers.add([block4, shortcut])\n",
        "# block4 = layers.ReLU()(block4)\n",
        "\n",
        "# shortcut = block4\n",
        "# block5 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block4)\n",
        "\n",
        "# block5 = layers.add([block5, shortcut])\n",
        "# block5 = layers.ReLU()(block5)\n",
        "\n",
        "# # third stage\n",
        "# shortcut = keras.Sequential([layers.Conv2D(filters=256, kernel_size=1, strides=2),\n",
        "#                              layers.BatchNormalization()])(block5)\n",
        "# block6 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block5)\n",
        "\n",
        "# block6 = layers.add([block6, shortcut])\n",
        "# block6 = layers.ReLU()(block6)\n",
        "\n",
        "# shortcut = block6\n",
        "# block7 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block6)\n",
        "\n",
        "# block7 = layers.add([block7, shortcut])\n",
        "# block7 = layers.ReLU()(block7)\n",
        "\n",
        "# #fourth stage\n",
        "# shortcut = keras.Sequential([layers.Conv2D(filters=512, kernel_size=1, strides=2),\n",
        "#                              layers.BatchNormalization()])(block7)\n",
        "# block8 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block7)\n",
        "\n",
        "# block8 = layers.add([block8, shortcut])\n",
        "# block8 = layers.ReLU()(block8)\n",
        "\n",
        "# shortcut = block8\n",
        "# block9 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block8)\n",
        "\n",
        "# block9 = layers.add([block9, shortcut])\n",
        "# block9 = layers.ReLU()(block9)\n",
        "\n",
        "# predictions = keras.Sequential([\n",
        "#     layers.GlobalAveragePooling2D(),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(10)\n",
        "# ])(block9)\n",
        "\n",
        "# model = keras.Model(inputs=image_input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q0TR4MI3A7oc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-06 22:26:10.121089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.126956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.127464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.128463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.128947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.129369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.683124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.683574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.684004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-06 22:26:10.684391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9601 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "## Applying bottleneck\n",
        "def bottleneck_block(input, filters=64, expansion=1, stride=1):\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # x = layers.Conv2D(filters, (3, 3), padding='same', strides=stride)(x)\n",
        "    x = layers.DepthwiseConv2D(3, padding='same', strides=stride)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters*expansion, (1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if (stride == 2 or expansion==4):\n",
        "        input = layers.Conv2D(filters*expansion, (1, 1), padding='same', strides=stride)(input)\n",
        "        input = layers.BatchNormalization()(input)\n",
        "\n",
        "    x = layers.Add()([x, input])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "kernel_initializer = 'he_normal'\n",
        "input_shape = (32,32,3)\n",
        "\n",
        "image_input = layers.Input(shape=input_shape)\n",
        "# first layer\n",
        "x = keras.Sequential([\n",
        "    layers.Conv2D(kernel_size=3, filters=64, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU()\n",
        "])(image_input)\n",
        "\n",
        "# first stage\n",
        "x = bottleneck_block(x, filters=64, expansion=1, stride=1)\n",
        "x = bottleneck_block(x, filters=64, expansion=1, stride=1)\n",
        "# second stage\n",
        "x = bottleneck_block(x, filters=128, expansion=1, stride=2)\n",
        "x = bottleneck_block(x, filters=128, expansion=1, stride=1)\n",
        "# Third stage\n",
        "x = bottleneck_block(x, filters=256, expansion=1, stride=2)\n",
        "x = bottleneck_block(x, filters=256, expansion=1, stride=1)\n",
        "# Fourth stage\n",
        "x = bottleneck_block(x, filters=512, expansion=1, stride=2)\n",
        "x = bottleneck_block(x, filters=512, expansion=1, stride=1)\n",
        "\n",
        "predictions = keras.Sequential([\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512),\n",
        "    layers.Dense(10)\n",
        "])(x)\n",
        "\n",
        "model = keras.Model(inputs=image_input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxph0-gRtlDr"
      },
      "outputs": [],
      "source": [
        "# from keras.callbacks import EarlyStopping\n",
        "# early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 30, mode = 'auto')\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(\n",
        "          x_train,\n",
        "          y_train,\n",
        "          epochs=1,\n",
        "          validation_split=0.1)\n",
        "          # callbacks = [early_stopping])\n",
        "\n",
        "# Total parameters\n",
        "model.summary()\n",
        "\n",
        "# Best Validation Accuracy\n",
        "print(\"Best Validation Accuracy:{:.4f}\".format(max(hist.history['val_accuracy'])))\n",
        "\n",
        "#plot training\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label = 'train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label = 'val loss')\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label = 'train accuracy')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label = 'val accuracy')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_xlabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc = 'upper left')\n",
        "acc_ax.legend(loc = 'lower left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "model.save(\"resnet18_rev\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkXdUL3yco0M"
      },
      "outputs": [],
      "source": [
        "# from tensorflow import keras\n",
        "# import tensorflow as tf\n",
        "# import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# load pre-trained model\n",
        "model = keras.models.load_model('resnet18_rev')\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
        "\n",
        "num_images = x_train.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(),\n",
        "]\n",
        "\n",
        "hist_prune = model_for_pruning.fit(x_train, y_train,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)\n",
        "\n",
        "# Best Validation Accuracy\n",
        "print(\"Best Validation Accuracy(Prunned):{.4f}\".format(max(hist_prune.history['val_accuracy'])))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
