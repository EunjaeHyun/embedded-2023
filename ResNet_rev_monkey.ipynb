{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy3NP4fsmgev",
        "outputId": "d0d35924-fd9b-4b0a-d642-fc41dab121b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 21:37:29.307112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-07 21:37:29.999123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
            "2023-11-07 21:37:29.999206: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
            "2023-11-07 21:37:29.999215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow_model_optimization\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers, datasets, utils, callbacks, optimizers, losses\n",
        "from keras.datasets import cifar10\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXOtrXiImuXd",
        "outputId": "0c289dd8-04cc-4ef2-c0cb-946077c705de"
      },
      "outputs": [],
      "source": [
        "# Loading data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Data Transform\n",
        "x_train = x_train.astype(np.float32) / 255.0\n",
        "y_train = utils.to_categorical(y_train)\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "\n",
        "x_test = x_test.astype(np.float32) / 255.0\n",
        "y_test = utils.to_categorical(y_test)\n",
        "x_test -= x_train_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZmQDOxbmhGU",
        "outputId": "62bb11a2-bf4a-46cb-b424-fdc22799ce06"
      },
      "outputs": [],
      "source": [
        "# Connect to google drive to save/load model\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdAgZtly1_XW"
      },
      "source": [
        "### ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MyQ5WtkTnGmO"
      },
      "outputs": [],
      "source": [
        "# # @title 기본 제목 텍스트\n",
        "# kernel_initializer = 'he_normal'\n",
        "# input_shape = (32,32,3)\n",
        "\n",
        "# image_input = layers.Input(shape=input_shape)\n",
        "# # first layer\n",
        "\n",
        "# block1 = keras.Sequential([\n",
        "#     layers.Conv2D(kernel_size=3, filters=64, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU()\n",
        "# ])(image_input)\n",
        "\n",
        "# # first stage\n",
        "# shortcut = block1\n",
        "# block2 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block1)\n",
        "\n",
        "# block2 = layers.add([block2, shortcut])\n",
        "# block2 = layers.ReLU()(block2)\n",
        "\n",
        "# shortcut = block2\n",
        "# block3 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block2)\n",
        "\n",
        "# block3 = layers.add([block3, shortcut])\n",
        "# block3 = layers.ReLU()(block3)\n",
        "\n",
        "# # second stage\n",
        "# shortcut = keras.Sequential([layers.Conv2D(filters=128, kernel_size=1, strides=2),\n",
        "#                              layers.BatchNormalization()])(block3)\n",
        "# block4 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block3)\n",
        "\n",
        "# block4 = layers.add([block4, shortcut])\n",
        "# block4 = layers.ReLU()(block4)\n",
        "\n",
        "# shortcut = block4\n",
        "# block5 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block4)\n",
        "\n",
        "# block5 = layers.add([block5, shortcut])\n",
        "# block5 = layers.ReLU()(block5)\n",
        "\n",
        "# # third stage\n",
        "# shortcut = keras.Sequential([layers.Conv2D(filters=256, kernel_size=1, strides=2),\n",
        "#                              layers.BatchNormalization()])(block5)\n",
        "# block6 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block5)\n",
        "\n",
        "# block6 = layers.add([block6, shortcut])\n",
        "# block6 = layers.ReLU()(block6)\n",
        "\n",
        "# shortcut = block6\n",
        "# block7 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block6)\n",
        "\n",
        "# block7 = layers.add([block7, shortcut])\n",
        "# block7 = layers.ReLU()(block7)\n",
        "\n",
        "# #fourth stage\n",
        "# shortcut = keras.Sequential([layers.Conv2D(filters=512, kernel_size=1, strides=2),\n",
        "#                              layers.BatchNormalization()])(block7)\n",
        "# block8 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block7)\n",
        "\n",
        "# block8 = layers.add([block8, shortcut])\n",
        "# block8 = layers.ReLU()(block8)\n",
        "\n",
        "# shortcut = block8\n",
        "# block9 = keras.Sequential([\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.ReLU(),\n",
        "#     layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "#     layers.BatchNormalization()\n",
        "# ])(block8)\n",
        "\n",
        "# block9 = layers.add([block9, shortcut])\n",
        "# block9 = layers.ReLU()(block9)\n",
        "\n",
        "# predictions = keras.Sequential([\n",
        "#     layers.GlobalAveragePooling2D(),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(10)\n",
        "# ])(block9)\n",
        "\n",
        "# model = keras.Model(inputs=image_input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0TR4MI3A7oc",
        "outputId": "9fe452f8-fba2-41df-ec1f-d1e3db7aa90b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 21:37:31.560983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:31.566220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:31.566703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:31.567443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-07 21:37:31.567886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:31.568344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:31.568794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:32.095228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:32.095693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:32.096269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-11-07 21:37:32.096804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9607 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 32, 32, 64)   2048        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   4160        ['sequential[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 32, 32, 64)  640         ['re_lu_1[0][0]']                \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 64)   0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'sequential[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 32, 32, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 64)  640         ['re_lu_4[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_5[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  're_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 32, 32, 64)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 128)  8320        ['re_lu_6[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 128)  1280       ['re_lu_7[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  8320        ['re_lu_6[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 128)  512        ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 16, 16, 128)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 128)  1280       ['re_lu_10[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 128)  512        ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  're_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 16, 16, 128)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 256)  33024       ['re_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 16, 16, 256)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 8, 8, 256)   2560        ['re_lu_13[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 8, 8, 256)    33024       ['re_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 8, 8, 256)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_15[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 8, 8, 256)   2560        ['re_lu_16[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_17[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_20[0][0]', \n",
            "                                                                  're_lu_15[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 8, 8, 256)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 512)    131584      ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 8, 8, 512)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 4, 4, 512)   5120        ['re_lu_19[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 4, 4, 512)   2048        ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 4, 4, 512)    262656      ['re_lu_20[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 4, 4, 512)    131584      ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_23[0][0]', \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 4, 4, 512)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 4, 4, 512)    262656      ['re_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 4, 4, 512)   5120        ['re_lu_22[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4, 4, 512)   2048        ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 4, 4, 512)    262656      ['re_lu_23[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_27[0][0]', \n",
            "                                                                  're_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 4, 4, 512)    0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 10)           267786      ['re_lu_24[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,713,034\n",
            "Trainable params: 1,699,594\n",
            "Non-trainable params: 13,440\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "## Applying bottleneck\n",
        "def bottleneck_block(input, filters=64, expansion=1, stride=1):\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # x = layers.Conv2D(filters, (3, 3), padding='same', strides=stride)(x)\n",
        "    x = layers.DepthwiseConv2D(3, padding='same', strides=stride)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters*expansion, (1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if (stride == 2 or expansion==4):\n",
        "        input = layers.Conv2D(filters*expansion, (1, 1), padding='same', strides=stride)(input)\n",
        "        input = layers.BatchNormalization()(input)\n",
        "\n",
        "    x = layers.Add()([x, input])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "kernel_initializer = 'he_normal'\n",
        "input_shape = (32,32,3)\n",
        "\n",
        "image_input = layers.Input(shape=input_shape)\n",
        "# first layer\n",
        "x = keras.Sequential([\n",
        "    layers.Conv2D(kernel_size=3, filters=64, strides=1, padding='same', kernel_initializer=kernel_initializer),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU()\n",
        "])(image_input)\n",
        "\n",
        "# first stage\n",
        "x = bottleneck_block(x, filters=64, expansion=1, stride=1)\n",
        "x = bottleneck_block(x, filters=64, expansion=1, stride=1)\n",
        "# second stage\n",
        "x = bottleneck_block(x, filters=128, expansion=1, stride=2)\n",
        "x = bottleneck_block(x, filters=128, expansion=1, stride=1)\n",
        "# Third stage\n",
        "x = bottleneck_block(x, filters=256, expansion=1, stride=2)\n",
        "x = bottleneck_block(x, filters=256, expansion=1, stride=1)\n",
        "# Fourth stage\n",
        "x = bottleneck_block(x, filters=512, expansion=1, stride=2)\n",
        "x = bottleneck_block(x, filters=512, expansion=1, stride=1)\n",
        "\n",
        "predictions = keras.Sequential([\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512),\n",
        "    layers.Dense(10)\n",
        "])(x)\n",
        "\n",
        "model = keras.Model(inputs=image_input, outputs=predictions)\n",
        "\n",
        "# Total parameters\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxph0-gRtlDr",
        "outputId": "e004c10a-8dea-487d-8601-2c85a6017416"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 21:37:33.170616: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 552960000 exceeds 10% of free system memory.\n",
            "2023-11-07 21:37:33.523921: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 552960000 exceeds 10% of free system memory.\n",
            "2023-11-07 21:37:40.560130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500\n",
            "2023-11-07 21:37:41.319579: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fe448edbdb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-07 21:37:41.319607: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
            "2023-11-07 21:37:41.324334: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-11-07 21:37:41.522624: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - ETA: 0s - loss: 1.4951 - accuracy: 0.4748"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 28). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/colab_data/best_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/colab_data/best_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 52s 24ms/step - loss: 1.4951 - accuracy: 0.4748 - val_loss: 1.2426 - val_accuracy: 0.5880\n",
            "Best Validation Accuracy:0.5880\n"
          ]
        }
      ],
      "source": [
        "# from keras.callbacks import EarlyStopping\n",
        "# early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 30, mode = 'auto')\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "save_dir = './drive/MyDrive/colab_data/'\n",
        "checkpoint = ModelCheckpoint(save_dir+\"best_model\", monitor=\"val_accuracy\", save_best_only=True, mode='auto')\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(\n",
        "          x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          validation_split=0.1,\n",
        "          callbacks = [checkpoint])\n",
        "\n",
        "# Best Validation Accuracy\n",
        "print(\"Best Validation Accuracy:{:.4f}\".format(max(hist.history['val_accuracy'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "MH0o1IdToE3z",
        "outputId": "3b0cc564-8eb8-411f-918e-ac29fa35b5a9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot training\n",
        "# %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label = 'train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label = 'val loss')\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label = 'train accuracy')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label = 'val accuracy')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_xlabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc = 'upper left')\n",
        "acc_ax.legend(loc = 'lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dir = './drive/MyDrive/colab_data/'\n",
        "model_best = keras.models.load_model(load_dir+'best_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pkXdUL3yco0M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   5/1407 [..............................] - ETA: 41s - loss: 0.0738 - accuracy: 0.9750    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0274s vs `on_train_batch_end` time: 0.1166s). Check your callbacks.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0274s vs `on_train_batch_end` time: 0.1166s). Check your callbacks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9713"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_1_layer_call_fn, re_lu_1_layer_call_and_return_conditional_losses while saving (showing 5 of 156). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/colab_data/pruned_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/colab_data/pruned_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 108s 56ms/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 0.9599 - val_accuracy: 0.8194\n",
            "Best Validation Accuracy(Prunned):0.8194\n"
          ]
        }
      ],
      "source": [
        "# from tensorflow import keras\n",
        "# import tensorflow as tf\n",
        "# import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
        "\n",
        "num_images = x_train.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model_best, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model_for_pruning.summary()\n",
        "save_dir = './drive/MyDrive/colab_data/'\n",
        "checkpoint = ModelCheckpoint(save_dir+\"pruned_model\", save_best_only=False)\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=save_dir),\n",
        "  checkpoint\n",
        "]\n",
        "\n",
        "hist_prune = model_for_pruning.fit(x_train, y_train,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)\n",
        "\n",
        "# Best Validation Accuracy\n",
        "print(\"Best Validation Accuracy(Prunned):{:.4f}\".format(max(hist_prune.history['val_accuracy'])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soJM27pyDTmZ",
        "outputId": "6e024644-e01f-44b3-e5bd-57e26849df8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 32, 32, 64)   2048        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   4160        ['sequential[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[2][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_1[2][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 32, 32, 64)  640         ['re_lu_1[2][0]']                \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d[2][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_2[2][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_2[2][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_2[2][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 64)   0           ['batch_normalization_3[2][0]',  \n",
            "                                                                  'sequential[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 32, 32, 64)   0           ['add[2][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_3[2][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_3[2][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_4[2][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 64)  640         ['re_lu_4[2][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d_1[2][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_5[2][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_5[2][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_4[2][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_6[2][0]',  \n",
            "                                                                  're_lu_3[2][0]']                \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 32, 32, 64)   0           ['add_1[2][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 128)  8320        ['re_lu_6[2][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_5[2][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_7[2][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 128)  1280       ['re_lu_7[2][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['depthwise_conv2d_2[2][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_8[2][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_8[2][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  8320        ['re_lu_6[2][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[2][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 128)  512        ['conv2d_7[2][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_9[2][0]',  \n",
            "                                                                  'batch_normalization_10[2][0]'] \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 16, 16, 128)  0           ['add_2[2][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_9[2][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['conv2d_8[2][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_11[2][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 128)  1280       ['re_lu_10[2][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_3[2][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_12[2][0]'] \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_11[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 128)  512        ['conv2d_9[2][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_13[2][0]', \n",
            "                                                                  're_lu_9[2][0]']                \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 16, 16, 128)  0           ['add_3[2][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 256)  33024       ['re_lu_12[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_10[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 16, 16, 256)  0           ['batch_normalization_14[2][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 8, 8, 256)   2560        ['re_lu_13[2][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_4[2][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_15[2][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_14[2][0]']               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 8, 8, 256)    33024       ['re_lu_12[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_11[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_12[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_16[2][0]', \n",
            "                                                                  'batch_normalization_17[2][0]'] \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 8, 8, 256)    0           ['add_4[2][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_15[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_13[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_18[2][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 8, 8, 256)   2560        ['re_lu_16[2][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_5[2][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_19[2][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_17[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_14[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_20[2][0]', \n",
            "                                                                  're_lu_15[2][0]']               \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 8, 8, 256)    0           ['add_5[2][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 512)    131584      ['re_lu_18[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_15[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 8, 8, 512)    0           ['batch_normalization_21[2][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 4, 4, 512)   5120        ['re_lu_19[2][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 4, 4, 512)   2048        ['depthwise_conv2d_6[2][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_22[2][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 4, 4, 512)    262656      ['re_lu_20[2][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 4, 4, 512)    131584      ['re_lu_18[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_16[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_17[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_23[2][0]', \n",
            "                                                                  'batch_normalization_24[2][0]'] \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 4, 4, 512)    0           ['add_6[2][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 4, 4, 512)    262656      ['re_lu_21[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_18[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_25[2][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 4, 4, 512)   5120        ['re_lu_22[2][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4, 4, 512)   2048        ['depthwise_conv2d_7[2][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_26[2][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 4, 4, 512)    262656      ['re_lu_23[2][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_19[2][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_27[2][0]', \n",
            "                                                                  're_lu_21[2][0]']               \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 4, 4, 512)    0           ['add_7[2][0]']                  \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 10)           267786      ['re_lu_24[2][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,713,034\n",
            "Trainable params: 1,699,594\n",
            "Non-trainable params: 13,440\n",
            "__________________________________________________________________________________________________\n",
            "Total Sparsity: 0.7966\n"
          ]
        }
      ],
      "source": [
        "# Total parameters after prune\n",
        "load_dir = './drive/MyDrive/colab_data/'\n",
        "pruned_model = tf.keras.models.load_model(load_dir+\"pruned_model\")\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "model_for_export.summary()\n",
        "\n",
        "pruned_weights = model_for_export.get_weights()\n",
        "\n",
        "# print sparsity\n",
        "total_count = 0\n",
        "total_nonzero = 0\n",
        "\n",
        "for i, weights in enumerate(pruned_weights):\n",
        "    if len(weights) > 0:\n",
        "        weight_matrix = np.array(weights[0])\n",
        "        non_zero_count = np.count_nonzero(weight_matrix)\n",
        "        layer_count = np.prod(weight_matrix.shape)\n",
        "        sparsity = 1.0 - (non_zero_count / layer_count)\n",
        "        # print(f\"Layer {i:>2d}: Sparsity = {sparsity:.4f}\")\n",
        "        total_count = total_count + layer_count\n",
        "        total_nonzero = total_nonzero + non_zero_count\n",
        "\n",
        "total_sparsity = 1.0 - (total_nonzero / total_count)\n",
        "print(f\"Total Sparsity: {total_sparsity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "OEDA71lhkWXq",
        "outputId": "1988cf0a-cb6b-4770-e8ff-0bdedb6b742d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist_prune.history['loss'], 'y', label = 'train loss')\n",
        "loss_ax.plot(hist_prune.history['val_loss'], 'r', label = 'val loss')\n",
        "acc_ax.plot(hist_prune.history['accuracy'], 'b', label = 'train accuracy')\n",
        "acc_ax.plot(hist_prune.history['val_accuracy'], 'g', label = 'val accuracy')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_xlabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc = 'upper left')\n",
        "acc_ax.legend(loc = 'lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwGou2zTkbAw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
